name: Build All AAP Image Flavors (AWS)

on:
  workflow_dispatch:

env:
  PACKER_VERSION: "latest"
  PACKER_FILE: ./images/packer/aap.pkr.hcl
  INSTALLER_URL: ${{ secrets.INSTALLER_URL }}
  INSTALLER_REGISTRY_USERNAME: ${{ secrets.INSTALLER_REGISTRY_USERNAME }}
  INSTALLER_REGISTRY_PASSWORD: ${{ secrets.INSTALLER_REGISTRY_PASSWORD }}
  INSTALLER_ADMIN_PW: ${{ secrets.INSTALLER_ADMIN_PW }}
  GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
  RHEL_USER_PASSWORD: ${{ secrets.RHEL_USER_PASSWORD }}

jobs:
  build:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        flavor: [CEH]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'us-east-1' }}

      - name: Set up Packer
        uses: hashicorp/setup-packer@main
        with:
          version: ${{ env.PACKER_VERSION }}

      - name: Run `packer init`
        id: init
        run: "packer init ${{ env.PACKER_FILE }}"

      - name: Run `packer validate`
        id: validate
        run: "packer validate ${{ env.PACKER_FILE }}"

      - name: Set build variables based on flavor
        run: |
          if [[ "${{ matrix.flavor }}" == "C" ]]; then
            export AAP_INCLUDE_CONTROLLER=true
            export AAP_INCLUDE_EDA_CONTROLLER=false
            export AAP_INCLUDE_AUTOMATION_HUB=false
          elif [[ "${{ matrix.flavor }}" == "CE" ]]; then
            export AAP_INCLUDE_CONTROLLER=true
            export AAP_INCLUDE_EDA_CONTROLLER=true
            export AAP_INCLUDE_AUTOMATION_HUB=false
          elif [[ "${{ matrix.flavor }}" == "CH" ]]; then
            export AAP_INCLUDE_CONTROLLER=true
            export AAP_INCLUDE_EDA_CONTROLLER=false
            export AAP_INCLUDE_AUTOMATION_HUB=true
          elif [[ "${{ matrix.flavor }}" == "CEH" ]]; then
            export AAP_INCLUDE_CONTROLLER=true
            export AAP_INCLUDE_EDA_CONTROLLER=true
            export AAP_INCLUDE_AUTOMATION_HUB=true
          fi

          echo "AAP_INCLUDE_CONTROLLER=${AAP_INCLUDE_CONTROLLER}" >> $GITHUB_ENV
          echo "AAP_INCLUDE_EDA_CONTROLLER=${AAP_INCLUDE_EDA_CONTROLLER}" >> $GITHUB_ENV
          echo "AAP_INCLUDE_AUTOMATION_HUB=${AAP_INCLUDE_AUTOMATION_HUB}" >> $GITHUB_ENV

      - name: Build AAP Image
        run: |
          echo "AWS_DEFAULT_REGION: $AWS_DEFAULT_REGION"
          echo "AWS_REGION: $AWS_REGION"
          echo "AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:0:10}..."
          packer build \
            -var "aws_region=${{ secrets.AWS_REGION || 'us-east-1' }}" \
            -var "aap_include_controller=${AAP_INCLUDE_CONTROLLER}" \
            -var "aap_include_eda_controller=${AAP_INCLUDE_EDA_CONTROLLER}" \
            -var "aap_include_automation_hub=${AAP_INCLUDE_AUTOMATION_HUB}" \
            -force ${{ env.PACKER_FILE }}

      - name: Get AMI ID and extract version
        id: get-ami
        run: |
          # Get the AMI ID directly from Packer build
          AMI_ID=$(jq -r '.builds[0].artifact_id' manifest.json | cut -d: -f2)
          echo "Found AMI ID: $AMI_ID"
          
          # Extract version from the file downloaded from Packer build
          if [ -f /tmp/aap_version_*.txt ]; then
            AAP_VERSION=$(cat /tmp/aap_version_*.txt | tr -d "[]'\"" | sed 's/bundle-//' | sed 's/-x86_64//')
            echo "Extracted AAP Version from Packer build: $AAP_VERSION"
          elif [ -f /tmp/version.txt ]; then
            AAP_VERSION=$(grep installer_version /tmp/version.txt | cut -d= -f2 | tr -d "[]'\"" | sed 's/bundle-//' | sed 's/-x86_64//')
            echo "Extracted AAP Version from version.txt: $AAP_VERSION"
          else
            # Fallback: extract from installer URL if version files not available
            AAP_VERSION=$(echo "${{ env.INSTALLER_URL }}" | grep -oP 'setup-\K[0-9]+\.[0-9]+-[0-9]+' || echo "2.5-17")
            echo "Using version from URL fallback: $AAP_VERSION"
          fi
          
          # Output variables for export step
          echo "ami_id=$AMI_ID" >> $GITHUB_OUTPUT
          echo "aap_version=$AAP_VERSION" >> $GITHUB_OUTPUT
          echo "Using AMI: $AMI_ID with version $AAP_VERSION"

      - name: Export AMI to S3 as qcow2
        id: export-ami
        env:
          AWS_DEFAULT_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}
        run: |
          # Set variables
          AMI_ID="${{ steps.get-ami.outputs.ami_id }}"
          S3_BUCKET="${{ secrets.S3_BUCKET_NAME || 'aap-qcow2-images' }}"
          FLAVOR_LOWER=$(echo "${{ matrix.flavor }}" | tr '[:upper:]' '[:lower:]')
          EXPORT_TASK_NAME="aap-$FLAVOR_LOWER-$(date +%Y%m%d-%H%M%S)"
          
          echo "Exporting AMI $AMI_ID to S3 bucket: s3://$S3_BUCKET (root)"
          
          # Create VM export task (using raw format as QCOW2 is not supported)
          EXPORT_TASK_ID=$(aws ec2 export-image \
            --image-id "$AMI_ID" \
            --disk-image-format raw \
            --s3-export-location S3Bucket="$S3_BUCKET",S3Prefix="" \
            --description "AAP $FLAVOR_LOWER raw export from $AMI_ID (for qcow2 conversion)" \
            --tag-specifications "ResourceType=export-image-task,Tags=[{Key=Name,Value=$EXPORT_TASK_NAME},{Key=Flavor,Value=$FLAVOR_LOWER},{Key=BuildDate,Value=$(date +%Y-%m-%d)}]" \
            --query 'ExportImageTaskId' \
            --output text)
          
          echo "export_task_id=$EXPORT_TASK_ID" >> $GITHUB_OUTPUT
          echo "Started export task: $EXPORT_TASK_ID"

      - name: Wait for export completion
        id: wait-export
        run: |
          EXPORT_TASK_ID="${{ steps.export-ami.outputs.export_task_id }}"
          echo "Monitoring export task: $EXPORT_TASK_ID"
          
          # Wait for export to complete (timeout after 2 hours)
          TIMEOUT=7200
          ELAPSED=0
          INTERVAL=30
          
          while [ $ELAPSED -lt $TIMEOUT ]; do
            STATUS=$(aws ec2 describe-export-image-tasks \
              --export-image-task-ids "$EXPORT_TASK_ID" \
              --query 'ExportImageTasks[0].Status' \
              --output text)
            
            PROGRESS=$(aws ec2 describe-export-image-tasks \
              --export-image-task-ids "$EXPORT_TASK_ID" \
              --query 'ExportImageTasks[0].Progress' \
              --output text)
            
            echo "Export status: $STATUS, Progress: $PROGRESS%"
            
            if [ "$STATUS" = "completed" ]; then
              S3_BUCKET="${{ secrets.S3_BUCKET_NAME || 'aap-qcow2-images' }}"
              
              # Debug: Show full export task details
              echo "Debug: Export task details:"
              aws ec2 describe-export-image-tasks --export-image-task-ids "$EXPORT_TASK_ID"
              
              # Get the actual S3 key from AWS (since AWS generates its own filename)
              S3_KEY=$(aws ec2 describe-export-image-tasks \
                --export-image-task-ids "$EXPORT_TASK_ID" \
                --query 'ExportImageTasks[0].S3ExportLocation.S3Key' \
                --output text)
              
              echo "Debug: Retrieved S3_KEY='$S3_KEY'"
              
              if [ "$S3_KEY" = "None" ] || [ -z "$S3_KEY" ] || [ "$S3_KEY" = "null" ]; then
                echo "Error: Unable to retrieve S3_KEY from AWS. Checking S3 bucket for recent files..."
                # List most recent files in S3 bucket
                aws s3 ls s3://$S3_BUCKET/ --recursive | tail -5
                echo "Using fallback: finding most recent .raw file in bucket"
                S3_KEY=$(aws s3 ls s3://$S3_BUCKET/ --recursive | grep "\.raw$" | tail -1 | awk '{print $4}')
                echo "Found S3_KEY via fallback: '$S3_KEY'"
                
                if [ -z "$S3_KEY" ]; then
                  echo "Error: No .raw file found in S3 bucket. Export may have failed."
                  exit 1
                fi
              fi
              
              echo "AWS generated S3 key: $S3_KEY"
              
              echo "Raw image export completed!"
              echo "Raw image available at: s3://$S3_BUCKET/$S3_KEY"
              
              # Convert raw to qcow2 using qemu-img in a container
              echo "Converting raw image to qcow2 format..."
              RAW_FILE=$(basename "$S3_KEY")
              
              # Create a cleaner qcow2 filename with AAP version
              FLAVOR_LOWER=$(echo "${{ matrix.flavor }}" | tr '[:upper:]' '[:lower:]')
              AAP_VERSION="${{ steps.get-ami.outputs.aap_version || '2.5-17' }}"
              QCOW2_FILE="aap-${AAP_VERSION}-${FLAVOR_LOWER}-$(date +%Y%m%d).qcow2"
              
              # Download raw image
              echo "Downloading raw image..."
              aws s3 cp "s3://$S3_BUCKET/$S3_KEY" "$RAW_FILE"
              
              # Install podman if not available, fallback to docker
              if ! command -v podman &> /dev/null; then
                echo "Installing podman..."
                sudo apt-get update -q
                sudo apt-get install -y podman
              fi
              
              # Convert to qcow2 using Podman (with Docker fallback)
              echo "Converting to qcow2..."
              if command -v podman &> /dev/null; then
                podman run --rm -v "$(pwd):/work" -w /work \
                  quay.io/libpod/qemu:latest \
                  qemu-img convert -f raw -O qcow2 "$RAW_FILE" "$QCOW2_FILE"
              else
                docker run --rm -v "$(pwd):/work" -w /work \
                  quay.io/libpod/qemu:latest \
                  qemu-img convert -f raw -O qcow2 "$RAW_FILE" "$QCOW2_FILE"
              fi
              
              # Upload qcow2 back to S3
              echo "Uploading qcow2 image..."
              aws s3 cp "$QCOW2_FILE" "s3://$S3_BUCKET/$QCOW2_FILE"
              
              # Clean up raw file from S3 to save storage costs
              echo "Removing raw file from S3..."
              aws s3 rm "s3://$S3_BUCKET/$S3_KEY"
              
              # Clean up local files
              rm -f "$RAW_FILE" "$QCOW2_FILE"
              
              echo "Conversion completed!"
              echo "qcow2 image available at: s3://$S3_BUCKET/$QCOW2_FILE"
              echo "Raw file removed from S3 to save storage costs"
              echo "s3_url=s3://$S3_BUCKET/$QCOW2_FILE" >> $GITHUB_OUTPUT
              break
            elif [ "$STATUS" = "cancelled" ] || [ "$STATUS" = "cancelling" ]; then
              echo "Export was cancelled"
              exit 1
            elif [ "$STATUS" = "failed" ]; then
              echo "Export failed"
              aws ec2 describe-export-image-tasks --export-image-task-ids "$EXPORT_TASK_ID"
              exit 1
            fi
            
            sleep $INTERVAL
            ELAPSED=$((ELAPSED + INTERVAL))
          done
          
          if [ $ELAPSED -ge $TIMEOUT ]; then
            echo "Export timed out after 2 hours"
            exit 1
          fi

      - name: Cleanup AWS resources  
        if: always()
        run: |
          AMI_ID="${{ steps.get-ami.outputs.ami_id }}"
          
          if [ -n "$AMI_ID" ] && [ "$AMI_ID" != "null" ]; then
            echo "Cleaning up AWS resources for AMI: $AMI_ID"
            
            # Get snapshot IDs associated with the AMI
            SNAPSHOT_IDS=$(aws ec2 describe-images \
              --image-ids "$AMI_ID" \
              --query 'Images[0].BlockDeviceMappings[*].Ebs.SnapshotId' \
              --output text \
              --region ${{ secrets.AWS_REGION || 'us-east-1' }} || echo "")
            
            # Deregister the AMI
            echo "Deregistering AMI: $AMI_ID"
            aws ec2 deregister-image \
              --image-id "$AMI_ID" \
              --region ${{ secrets.AWS_REGION || 'us-east-1' }} || echo "Failed to deregister AMI"
            
            # Delete associated snapshots
            if [ -n "$SNAPSHOT_IDS" ] && [ "$SNAPSHOT_IDS" != "None" ]; then
              for SNAPSHOT_ID in $SNAPSHOT_IDS; do
                if [ "$SNAPSHOT_ID" != "None" ]; then
                  echo "Deleting snapshot: $SNAPSHOT_ID"
                  aws ec2 delete-snapshot \
                    --snapshot-id "$SNAPSHOT_ID" \
                    --region ${{ secrets.AWS_REGION || 'us-east-1' }} || echo "Failed to delete snapshot $SNAPSHOT_ID"
                fi
              done
            fi
            
            echo "AWS cleanup completed"
          else
            echo "No AMI to cleanup"
          fi

      - name: Generate build summary
        if: success()
        run: |
          echo "## AAP Image Build Complete - Flavor: ${{ matrix.flavor }}" >> $GITHUB_STEP_SUMMARY
          echo "**AMI Name:** ${{ steps.get-ami.outputs.final_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**S3 Location:** ${{ steps.wait-export.outputs.s3_url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Build Date:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "**Components:**" >> $GITHUB_STEP_SUMMARY
          echo "- Controller: ${AAP_INCLUDE_CONTROLLER}" >> $GITHUB_STEP_SUMMARY
          echo "- EDA: ${AAP_INCLUDE_EDA_CONTROLLER}" >> $GITHUB_STEP_SUMMARY
          echo "- Hub: ${AAP_INCLUDE_AUTOMATION_HUB}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Note:** AMI and snapshots have been automatically cleaned up to save costs." >> $GITHUB_STEP_SUMMARY

      # - name: Capture installer details from Packer
      #   if: success()
      #   run: |
      #     if [[ -f /tmp/version.txt ]]; then
      #       while IFS='=' read -r key value; do
      #         echo "$key=$value" >> $GITHUB_ENV
      #       done < /tmp/version.txt
      #     fi

      # - name: Generate workflow summary
      #   run: |
      #     echo "### AAP Image Build Summary" >> $GITHUB_STEP_SUMMARY
      #     echo "**Installer Filename:** ${{ env.installer_filename }}" >> $GITHUB_STEP_SUMMARY
      #     echo "**Installer SHA-256 Checksum:** ${{ env.installer_checksum }}" >> $GITHUB_STEP_SUMMARY
